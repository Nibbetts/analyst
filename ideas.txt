
SRC

abstract - high level, key points, what we learned. look up word number.
Submit to Nancy wednesday 7th!

abstract for presentation is similar to abstract for a research paper -
look up examples.

go for 3 min?





run litmus test to see how much signal we are getting - pause in development.
try to have done by next friday.
use slim (or even slimmer) version, compare with same words with totally
randomized normalized vectors and see if we can see numerical differences,
or if just specific inspection is useful.

!!!!!!!DON"T PRINT THINGS WE DIDN"T ASK FOR!!








average distance to nearest; nearest n
average distance to furthest; furthest n
average distance

find words where nearest are each other (these are nodes),
    then recursively find all words whose nearest are one of these, and so on.
    This should find peaks, or local concentrations; turn these into clusters.
    note: may end up with nearly num_words/2 clusters
    print percent of words that are part of a node
find words whose farthest are each other.
    Find out for how many these are also furthest; make anti-clusters?
find average distance between words in "clusters".
    Some nodes will be closer than this, and to more than one cluster.
    But if we add all, may end up with one giant cluster.
    May label those further than this as outliers?
    Use avg dist between words in node-pairs as cutoff for outliers instead of avg dist of that cluster?
    Make new entity called "core" of all within that distance; primary dispersion measurement on this? Or would this simply be like the same as avg node width?
make function to print primary components of cluster; nodes/those closest.

make function to take in word/vec list and make a cluster based on it,
    then find all other words likely to belong to this cluster.
    This is useful since certain types of clusters will frequently overlap and words will belong to multiple classes.
    Then can measure purity of cluster based on user feed-back of what words didn't belong.
    Could use this feedback to analyze important dimensional components of cluster; where to extend and where to stop;
    can also measure extremity of cluster before and after this, representing misshapenness.

Hierarchicality:
    nodal factor/shattered factor: num words that are part of a node divided by num not
    hierarchical facter (burst factor is 1-this or 1/this?):
        num nodes that are part of supernodes versus num not

Have each node store a vector representation of the line from a to b,
    normalize them, then compute an average abs(dot product) of these,
    as a measure of alignment of nodes.
    Get some sort of distribution graph of node lengths, like we did with word distances.

embedysis
encodysis
wordalysis
embedology
vectorology
vectoralysis



try projecting each word vector onto its major axis and see how they are related. (Darian's Idea)



def shift(string, k=1):
    # Usefuls start at 32 and end at 126. So mod by 127-32=95.
    s = ""
    for c in string:
        n = ord(c)
        if n >= 32 and n <= 126:
            s += chr((n-32 + k) % 95 + 32)
        else: s += c
    return s
