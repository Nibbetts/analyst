A Place Where Deprecated Code Goes to Die...
--------------------------------------------------------------------------------    

//FROM ANALYST:

    # # Nuclei:
    # if "Nuclei" in self.categories:
    #     self.nuclei = clusters.clusterizer.compute_nuclei()
    #     self._print("Performing Cold Fusion")
    #     self._add_cluster_type_attributes(self.nuclei, "Nuclei")

    # # Anti-hubs:
    # if "Anti-hubs" in self.categories:
    #     self.anti_hubs = clusters.clusterizer.compute_anti_hubs()
    #     self._print("Unraveling the Secrets of Dark Matter")
    #     self._add_cluster_type_attributes(self.anti_hubs, "Anti-hubs")





self.strings = None
if callable(encoder) or encoder is None:
    self.encode = encoder # string to vector
    self.decode = decoder # vector to string
else:
    assert len(encoder) == len(self.space)
    self.strings = encoder
    self.vec_to_s = {}
    self.s_to_vec = {}
    for i in range(len(self.space)):
        self.vec_to_s[self.space[i]] = self.strings[i]
        self.s_to_vec[self.strings[i]] = self.space[i]
    self.encode = self.s_to_vec.__getitem__
    self.decode = self.vec_to_s.__getitem__




"""
def _serialize(self):
    # method to prepare an analyst instance for saving.
    if not self.serialized:
        self.metric = self.metric.__name__ if self.metric != None else None
        self.encode = self.encode.__name__ if self.encode != None else None
        self.decode = self.decode.__name__ if self.decode != None else None
        self.cluster_algorithms = [
            (None, pair[1]) for pair in self.cluster_algorithms]
        self.analogy_algorithms = [
            (None, pair[1]) for pair in self.analogy_algorithms]

        # Serialize the Clusters (Nodes don't need it):
        for key in self.cluster_data:
            for cluster in self.cluster_data[key]:
                cluster._serialize()

        self.serialized = True

def _deserialize(self, metric, encoder, decoder,
                    cluster_algorithms, analogy_algorithms):
    assert self.serialized
    if callable(metric):
        assert metric.__name__ == self.metric
        self.metric = metric
    elif metric == "l2" or metric == "euclidean":
        self.metric = sp.distance.euclidean
    elif metric == "cosine_similarity":
        self.metric = sp.distance.cosine
    elif metric == "l1":
        self.metric = sp.distance.cityblock
    else: raise ValueError("'metric' parameter unrecognized and uncallable")            
        
    if encoder != None: assert encoder.__name__ == self.encode
    self.encode = encoder
    if decoder != None: assert decoder.__name__ == self.decode
    self.decode = decoder

    if cluster_algorithms != None:
        assert zip(*cluster_algorithms)[1] == zip(*self.cluster_algorithms)[1]
    self.cluster_algorithms = cluster_algorithms
    if analogy_algorithms != None:
        assert zip(*analogy_algorithms)[1] == zip(*self.analogy_algorithms)[1]
    self.analogy_algorithms = analogy_algorithms

    # Deserialize the Clusters:
    for key in self.cluster_data:
        for cluster in self.cluster_data[key]:
            cluster._deserialize(metric, encoder, decoder)

    self.serialized = False
"""


--------------------------------------------------------------------------------
NOT DEPRECATED, BUT UNSURE AND HOMELESS:
--------------------------------------------------------------------------------

# Specific Functions:
def rescale(self, theta, alpha=15, power=0.5):
    ''' Rescales based on observed distribution of angles between words
        in a postagged Wikipedia word embedding from BYU PCCL.
        Accepts theta in radians.'''
    return (0.5 + (math.atan((theta*180/np.pi - 90)/alpha)
                    / (2*math.atan(90/alpha))))**power

def test_angles(self, n, alpha=15, power=0.5):
    dist = [self.rescale(self.s.angle(
                self.s.get_vector(self.s.model.vocab[int(x)]),
                self.s.get_vector(self.s.model.vocab[int(2*x)])),
                alpha, power)
            for x in (np.random.random(n)*len(self.s.model.vocab)/2.0)]
    plt.hist(dist, 90)
    plt.show()

#def scale_bimodal(self, theta):
#    deg = theta*180/np.pi
#    return 0.5 + (self.cbrt((deg-90)) / (2*self.cbrt(90)))

def cluster_analogy(self, A, B, C, AC_clustername, B_clustername,
                    num_words=1, exclude=True):
    ''' Follows form: A:B::C:D.
        Assumes that we know which cluster each word comes from.'''
    dist = self.s.get_angle(A, B)
    A_tighter = (self.clusters[AC_clustername][1]
                <= self.clusters[B_clustername][1]
    C_vec = self.s.get_vector(C)
    dir_vec = self.clusters[AC_clustername][0] - C_vec
    if A_tighter: dir_vec = -dir_vec
    D_vec = self.s.yarax(C_vec, dir_vec, dist)
    D_vec /= np.linalg.norm(D_vec)

    if exclude:
        if self.s.slim == True: # This branch other part of patch:
            results = self.s.wordify(
                self.s.model.get_closest_words(D_vec, num_words+3))
            trimmed = ([word for word in results[0]
                        if word not in [A, B, C]],
                    [results[1][i] for i in range(len(results[1]))
                        if results[0][i] not in [A, B, C]])
            return (np.array(trimmed[0][:num_words:]),
                    np.array(trimmed[1][:num_words:]))
        else: # This branch is the original return:
            return self.s.wordify(self.s.model.get_closest_words_excluding(
                D_vec, [self.s.get_vector(A), self.s.get_vector(B), C_vec],
                num_words))
    else: # The real original return...
        return self.s.wordify(
            self.s.model.get_closest_words(D_vec, num_words))

def divergence_analogy(self, A, B, C):
''' Automatically tries to find clusters around A and B,
    and then does a cluster analogy.'''
raise NotImplementedError("Function not implemented.")